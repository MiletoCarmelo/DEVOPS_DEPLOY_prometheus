==== ./umbrella_prometheus/values.yaml ====

kube-prometheus-stack:
  namespace: monitoring
  prometheusOperator:
    enabled: true
    createCustomResourceDefinitions: false  # Important: mettre à false car les CRDs doivent être installés séparément
    admissionWebhooks:
      enabled: false
      failurePolicy: Ignore  # Ajouter cette ligne
      patch:
        enabled: false  # Désactiver le patch de webhook
    tls:
      enabled: false
    serviceMonitor:
      enabled: true
      selfMonitor: true
      labels:
        app.kubernetes.io/managed-by: prometheus-operator
    serviceAccount:
      annotations:
        "kubectl.kubernetes.io/last-applied-configuration": ""

  prometheus:
    enabled: true
    prometheusSpec:
      serviceMonitorSelector:
        matchLabels:
          app.kubernetes.io/managed-by: prometheus-operator
      ruleSelector:
        matchLabels:
          app.kubernetes.io/managed-by: prometheus-operator
      serviceMonitorNamespaceSelector: {}
      ruleNamespaceSelector: {}
      retention: 15d
      resources:
        requests:
          memory: "256Mi"
          cpu: "100m"
        limits:
          memory: "512Mi"
          cpu: "200m"
      storageSpec:
        volumeClaimTemplate:
          spec:
            storageClassName: "local-path"  # même chose ici
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 10Gi
    serviceAccount:
      annotations:
        "kubectl.kubernetes.io/last-applied-configuration": ""

  grafana:
    enabled: true
    adminPassword: admin
    persistence:
      enabled: true
      size: 10Gi
    storageClassName: "local-path"  # ou une autre storageClass disponible dans votre cluster
    sidecar:
      dashboards:
        enabled: true
        label: grafana_dashboard
        searchNamespace: ALL
        defaultFolderName: "General"
        provider:
          folder: "General"
    plugins:
      - grafana-piechart-panel
      - grafana-clock-panel
    notifiers:
      default:
        name: email-notifier
        type: email
        uid: email1
    securityContext:
      runAsUser: 472
      runAsGroup: 472
      fsGroup: 472
    resources:
      requests:
        memory: 256Mi
        cpu: 100m
      limits:
        memory: 512Mi
        cpu: 200m
    ingress:
      enabled: true
      ingressClassName: nginx
      hosts:
        - grafana.local
      annotations:
        nginx.ingress.kubernetes.io/ssl-redirect: "false"
  serviceAccount:
      annotations:
        "kubectl.kubernetes.io/last-applied-configuration": ""

serviceMonitors:
  kafka:
    enabled: true
    groupVersion: monitoring.coreos.com/v1

prometheusRules:
  groupVersion: monitoring.coreos.com/v1

==== ./umbrella_prometheus/Chart.yaml ====

apiVersion: v2
name: prometheus-umbrella
description: Umbrella chart for Prometheus monitoring stack using kube-prometheus-stack
version: 0.1.4
dependencies:
  - name: kube-prometheus-stack
    version: 66.3.0
    repository: https://prometheus-community.github.io/helm-charts

==== ./umbrella_prometheus/templates/dashboards-configmap.yaml ====

apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards
  namespace: {{ .Release.Namespace }}
  labels:
    grafana_dashboard: "true"
    app: {{ .Release.Name }}
data:
  {{- range $path, $_ := .Files.Glob "dashboards/*.json.tpl" }}
  {{ base $path | trimSuffix ".tpl" }}: |
{{ $.Files.Get $path | indent 4 }}
  {{- end }}

==== ./umbrella_prometheus/templates/prometheusrules/custom-alerts.yaml ====

apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: prometheus-kube-prometheus-kafka-alerts
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/component: monitoring
    app.kubernetes.io/name: kube-prometheus-stack
    app.kubernetes.io/part-of: kube-prometheus-stack
    app.kubernetes.io/version: "v0.68.0"
spec:
  groupVersion: {{ .Values.prometheusRules.groupVersion }}  # Référence à values.yaml
  groups:
    - name: kubernetes-apps
      rules:
        - alert: PodCrashLooping
          expr: increase(kube_pod_container_status_restarts_total[1h]) > 5
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: Pod crashing multiple times
            description: 'Pod {{ `{{$labels.namespace}}` }}/{{ `{{$labels.pod}}` }} is restarting frequently'

        - alert: PodStuckInPending
          expr: kube_pod_status_phase{phase="Pending"} == 1
          for: 30m
          labels:
            severity: warning
          annotations:
            summary: Pod stuck in Pending state
            description: 'Pod {{ `{{$labels.namespace}}` }}/{{ `{{$labels.pod}}` }} has been in pending state for more than 30 minutes'

    - name: memory-alerts
      rules:
        - alert: HighMemoryUsage
          expr: container_memory_usage_bytes / container_spec_memory_limit_bytes * 100 > 85
          for: 15m
          labels:
            severity: warning
          annotations:
            summary: High memory usage detected
            description: 'Container {{ `{{$labels.container}}` }} in pod {{ `{{$labels.pod}}` }} is using more than 85% of its memory limit'

    - name: node-alerts
      rules:
        - alert: NodeDiskAlmostFull
          expr: disk_used_percent > 85
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: Node disk almost full
            description: 'Node {{ `{{$labels.instance}}` }} disk usage is {{ `{{$value}}` }}%'

    - name: kafka-alerts
      rules:
        - alert: KafkaTopicLag
          expr: kafka_consumergroup_lag > 10000
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: Kafka consumer group lag
            description: 'Consumer group {{ `{{$labels.consumergroup}}` }} on topic {{ `{{$labels.topic}}` }} is lagging by {{ `{{$value}}` }} messages'

    - name: service-alerts
      rules:
        - alert: HighErrorRate
          expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) * 100 > 5
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: High HTTP error rate
            description: 'Service {{ `{{$labels.service}}` }} has a {{ `{{$value}}` }}% error rate'

    - name: database-alerts
      rules:
        - alert: PostgresqlHighConnections
          expr: pg_stat_activity_count > 100
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: High number of PostgreSQL connections
            description: 'Database {{ `{{$labels.database}}` }} has {{ `{{$value}}` }} active connections'

==== ./umbrella_prometheus/templates/servicemonitors/kafka-monitor.yaml ====

{{- if .Values.serviceMonitors.kafka.enabled }}
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: prometheus-kube-prometheus-kafka  # Le nom est correct
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/managed-by: prometheus-operator  # Match avec le sélecteur
    release: {{ .Release.Name }}
spec:
  groupVersion: {{ .Values.serviceMonitors.kafka.groupVersion }}  # Référence à values.yaml
  selector:
    matchLabels:
      app: kafka
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
  namespaceSelector:
    matchNames:
      - kafka-dev
{{- end }}

