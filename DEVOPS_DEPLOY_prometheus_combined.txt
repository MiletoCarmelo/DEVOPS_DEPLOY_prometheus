==== ./umbrella_prometheus/values.yaml ====

kube-prometheus-stack:
  namespace: monitoring
  prometheusOperator:
    enabled: true
    createCustomResourceDefinitions: false
    admissionWebhooks:
      enabled: false
      failurePolicy: Fail  # Changement pour plus de sécurité
      patch:
        enabled: false
    tls:
      enabled: false
    serviceMonitor:
      enabled: true
      selfMonitor: true
      labels:
        app.kubernetes.io/managed-by: prometheus-operator
    serviceAccount:
      annotations:
        "kubectl.kubernetes.io/last-applied-configuration": ""

  prometheus:
    enabled: true
    prometheusSpec:
      serviceMonitorSelector:
        matchLabels:
          app.kubernetes.io/managed-by: prometheus-operator
      ruleSelector:
        matchLabels:
          app.kubernetes.io/managed-by: prometheus-operator
      serviceMonitorNamespaceSelector: {}
      ruleNamespaceSelector: {}
      retention: 15d
      resources:
        requests:
          memory: "256Mi"
          cpu: "100m"
        limits:
          memory: "512Mi"
          cpu: "200m"
      storageSpec:
        volumeClaimTemplate:
          spec:
            storageClassName: "local-path"
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 10Gi
    serviceAccount:
      annotations:
        "kubectl.kubernetes.io/last-applied-configuration": ""

  grafana:
    enabled: true
    adminPassword: admin  # Remplacer par un secret si nécessaire
    persistence:
      enabled: true
      size: 10Gi
    storageClassName: "local-path"
    sidecar:
      dashboards:
        enabled: true
        label: grafana_dashboard
        searchNamespace: ALL
        defaultFolderName: "General"
        provider:
          folder: "General"
    plugins:
      - grafana-piechart-panel
      - grafana-clock-panel
    securityContext:
      runAsUser: 472
      runAsGroup: 472
      fsGroup: 472
    resources:
      requests:
        memory: 256Mi
        cpu: 100m
      limits:
        memory: 512Mi
        cpu: 200m
    ingress:
      enabled: true
      ingressClassName: nginx
      hosts:
        - grafana.local  # Assure-toi que ce domaine résout correctement
      annotations:
        nginx.ingress.kubernetes.io/ssl-redirect: "false"

serviceMonitors:
  kafka:
    enabled: true
    namespace: kafka-dev
    scrapeInterval: 60s
    groupVersion: monitoring.coreos.com/v1

prometheusRules:
  groupVersion: monitoring.coreos.com/v1

kafka:
  lagThreshold: 5000


==== ./umbrella_prometheus/Chart.yaml ====

apiVersion: v2
name: prometheus-umbrella
description: Umbrella chart for Prometheus monitoring stack using kube-prometheus-stack
version: 0.1.1
maintainers:
  - name: Carmelo Mileto
    email: carmelo.mileto@gmail.com
dependencies:
  - name: kube-prometheus-stack
    version:  66.3.1
    repository: https://prometheus-community.github.io/helm-charts


==== ./umbrella_prometheus/templates/dashboards-configmap.yaml ====

apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards
  namespace: {{ .Release.Namespace }}
  labels:
    grafana_dashboard: "true"
    app: {{ .Release.Name }}
data:
  {{- range $path, $_ := .Files.Glob "dashboards/*.json.tpl" }}
  {{ base $path | trimSuffix ".tpl" }}: |
{{ $.Files.Get $path | indent 4 }}
  {{- end }}


==== ./umbrella_prometheus/templates/prometheusrules/custom-alerts.yaml ====

apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: prometheus-kube-prometheus-kafka-alerts
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/component: monitoring
    app.kubernetes.io/name: kube-prometheus-stack
    app.kubernetes.io/part-of: kube-prometheus-stack
    app.kubernetes.io/version: "v0.68.0"
spec:
  groupVersion: {{ .Values.prometheusRules.groupVersion }}
  groups:
    - name: kubernetes-apps
      rules:
        - alert: PodCrashLooping
          expr: increase(kube_pod_container_status_restarts_total[1h]) > 5
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: Pod crashing multiple times
            description: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} is restarting frequently'
        - alert: PodStuckInPending
          expr: kube_pod_status_phase{phase="Pending"} == 1
          for: 30m
          labels:
            severity: warning
          annotations:
            summary: Pod stuck in Pending state
            description: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in pending state for more than 30 minutes'

    - name: memory-alerts
      rules:
        - alert: HighMemoryUsage
          expr: container_memory_usage_bytes / container_spec_memory_limit_bytes * 100 > 85
          for: 15m
          labels:
            severity: warning
          annotations:
            summary: High memory usage detected
            description: 'Container {{ $labels.container }} in pod {{ $labels.pod }} is using more than 85% of its memory limit'

    - name: kafka-alerts
      rules:
        - alert: KafkaTopicLag
          expr: kafka_consumergroup_lag > {{ .Values.kafka.lagThreshold | default 5000 }}
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: Kafka consumer group lag
            description: 'Consumer group {{ $labels.consumergroup }} on topic {{ $labels.topic }} is lagging by {{ $value }} messages'


==== ./umbrella_prometheus/templates/servicemonitors/kafka-monitor.yaml ====

{{- if .Values.serviceMonitors.kafka.enabled }}
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: prometheus-kube-prometheus-kafka
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/managed-by: prometheus-operator
    release: {{ .Release.Name }}
spec:
  groupVersion: {{ .Values.serviceMonitors.kafka.groupVersion }}
  selector:
    matchLabels:
      app: kafka
  endpoints:
    - port: metrics
      interval: {{ .Values.serviceMonitors.kafka.scrapeInterval | default "30s" }}
      path: /metrics
  namespaceSelector:
    matchNames:
      - {{ .Values.serviceMonitors.kafka.namespace | default "default" }}
{{- end }}


